{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRAsZpOfcqgM"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3B7Zzb86c0KJ",
        "outputId": "69ecd6ab-7eba-4fb2-f419-9a441378a453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 7s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_images.shape)\n",
        "print(train_labels.shape)\n",
        "print(test_images.shape)\n",
        "print(test_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MIKHP4jc5Mp",
        "outputId": "c0c246ba-c281-440c-c55d-80725e5a6e6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(50000, 1)\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the pixels data to float type\n",
        "train_images = train_images.astype('float32')\n",
        "test_images = test_images.astype('float32')\n",
        " \n",
        "# Standardizing (255 is the total number of pixels an image can have)\n",
        "train_images = train_images / 255\n",
        "test_images = test_images / 255 \n",
        "\n",
        "# One hot encoding the target class (labels)\n",
        "num_classes = 10\n",
        "train_labels = np_utils.to_categorical(train_labels, num_classes)\n",
        "test_labels = np_utils.to_categorical(test_labels, num_classes)"
      ],
      "metadata": {
        "id": "_fwOjgClc5X_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a sequential model and adding layers to it\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(32,32,3)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Conv2D(32, (3,3), padding='same', activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(layers.Dropout(0.3))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(layers.Dropout(0.5))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(num_classes, activation='softmax'))    # num_classes = 10\n",
        "\n",
        "# Checking the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_KgUtg_eCOI",
        "outputId": "9c2cca49-2c05-4a34-c36a-3dbd1ee7bf34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32, 32, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 8, 8, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 8, 8, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               262272    \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 552,874\n",
            "Trainable params: 551,722\n",
            "Non-trainable params: 1,152\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "wDLojPPGeLrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_images, train_labels, batch_size=64, epochs=100,\n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKTojt5BeTlV",
        "outputId": "c40eb53a-4ef2-4196-855c-e6c373e337c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "782/782 [==============================] - 30s 15ms/step - loss: 1.7358 - accuracy: 0.4031 - val_loss: 1.2781 - val_accuracy: 0.5307\n",
            "Epoch 2/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 1.1645 - accuracy: 0.5826 - val_loss: 1.0106 - val_accuracy: 0.6417\n",
            "Epoch 3/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.9752 - accuracy: 0.6589 - val_loss: 0.9080 - val_accuracy: 0.6835\n",
            "Epoch 4/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.8730 - accuracy: 0.6945 - val_loss: 0.8182 - val_accuracy: 0.7106\n",
            "Epoch 5/100\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.8078 - accuracy: 0.7181 - val_loss: 0.7167 - val_accuracy: 0.7490\n",
            "Epoch 6/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.7483 - accuracy: 0.7398 - val_loss: 0.7131 - val_accuracy: 0.7570\n",
            "Epoch 7/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.7112 - accuracy: 0.7540 - val_loss: 0.5996 - val_accuracy: 0.7922\n",
            "Epoch 8/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.6733 - accuracy: 0.7676 - val_loss: 0.5675 - val_accuracy: 0.8036\n",
            "Epoch 9/100\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.6471 - accuracy: 0.7766 - val_loss: 0.6396 - val_accuracy: 0.7806\n",
            "Epoch 10/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.6189 - accuracy: 0.7879 - val_loss: 0.7211 - val_accuracy: 0.7531\n",
            "Epoch 11/100\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.5962 - accuracy: 0.7942 - val_loss: 0.5494 - val_accuracy: 0.8138\n",
            "Epoch 12/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.5731 - accuracy: 0.8031 - val_loss: 0.5305 - val_accuracy: 0.8176\n",
            "Epoch 13/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.5615 - accuracy: 0.8063 - val_loss: 0.5261 - val_accuracy: 0.8239\n",
            "Epoch 14/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.5394 - accuracy: 0.8160 - val_loss: 0.5193 - val_accuracy: 0.8201\n",
            "Epoch 15/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.5260 - accuracy: 0.8204 - val_loss: 0.5050 - val_accuracy: 0.8272\n",
            "Epoch 16/100\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.5081 - accuracy: 0.8267 - val_loss: 0.5425 - val_accuracy: 0.8206\n",
            "Epoch 17/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.5057 - accuracy: 0.8248 - val_loss: 0.5071 - val_accuracy: 0.8289\n",
            "Epoch 18/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4923 - accuracy: 0.8286 - val_loss: 0.4838 - val_accuracy: 0.8368\n",
            "Epoch 19/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4822 - accuracy: 0.8348 - val_loss: 0.4835 - val_accuracy: 0.8363\n",
            "Epoch 20/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4694 - accuracy: 0.8381 - val_loss: 0.5066 - val_accuracy: 0.8350\n",
            "Epoch 21/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4685 - accuracy: 0.8388 - val_loss: 0.4647 - val_accuracy: 0.8433\n",
            "Epoch 22/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4540 - accuracy: 0.8437 - val_loss: 0.4511 - val_accuracy: 0.8496\n",
            "Epoch 23/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4474 - accuracy: 0.8461 - val_loss: 0.4658 - val_accuracy: 0.8448\n",
            "Epoch 24/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4393 - accuracy: 0.8508 - val_loss: 0.4596 - val_accuracy: 0.8514\n",
            "Epoch 25/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4363 - accuracy: 0.8496 - val_loss: 0.4634 - val_accuracy: 0.8464\n",
            "Epoch 26/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4245 - accuracy: 0.8551 - val_loss: 0.4373 - val_accuracy: 0.8583\n",
            "Epoch 27/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4213 - accuracy: 0.8573 - val_loss: 0.4500 - val_accuracy: 0.8480\n",
            "Epoch 28/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4190 - accuracy: 0.8556 - val_loss: 0.4537 - val_accuracy: 0.8497\n",
            "Epoch 29/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4109 - accuracy: 0.8593 - val_loss: 0.4618 - val_accuracy: 0.8507\n",
            "Epoch 30/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3996 - accuracy: 0.8633 - val_loss: 0.4480 - val_accuracy: 0.8501\n",
            "Epoch 31/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4030 - accuracy: 0.8604 - val_loss: 0.4446 - val_accuracy: 0.8547\n",
            "Epoch 32/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3928 - accuracy: 0.8651 - val_loss: 0.4391 - val_accuracy: 0.8529\n",
            "Epoch 33/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3887 - accuracy: 0.8660 - val_loss: 0.4588 - val_accuracy: 0.8484\n",
            "Epoch 34/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3866 - accuracy: 0.8664 - val_loss: 0.4248 - val_accuracy: 0.8610\n",
            "Epoch 35/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3791 - accuracy: 0.8683 - val_loss: 0.4147 - val_accuracy: 0.8620\n",
            "Epoch 36/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3770 - accuracy: 0.8695 - val_loss: 0.4644 - val_accuracy: 0.8430\n",
            "Epoch 37/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3736 - accuracy: 0.8697 - val_loss: 0.4235 - val_accuracy: 0.8608\n",
            "Epoch 38/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3695 - accuracy: 0.8730 - val_loss: 0.4635 - val_accuracy: 0.8451\n",
            "Epoch 39/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3634 - accuracy: 0.8745 - val_loss: 0.4060 - val_accuracy: 0.8640\n",
            "Epoch 40/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3612 - accuracy: 0.8766 - val_loss: 0.4765 - val_accuracy: 0.8488\n",
            "Epoch 41/100\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.3552 - accuracy: 0.8765 - val_loss: 0.4808 - val_accuracy: 0.8422\n",
            "Epoch 42/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3587 - accuracy: 0.8763 - val_loss: 0.4037 - val_accuracy: 0.8681\n",
            "Epoch 43/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3448 - accuracy: 0.8819 - val_loss: 0.4268 - val_accuracy: 0.8632\n",
            "Epoch 44/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3469 - accuracy: 0.8801 - val_loss: 0.5024 - val_accuracy: 0.8396\n",
            "Epoch 45/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3375 - accuracy: 0.8821 - val_loss: 0.4309 - val_accuracy: 0.8648\n",
            "Epoch 46/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3404 - accuracy: 0.8821 - val_loss: 0.4227 - val_accuracy: 0.8653\n",
            "Epoch 47/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3401 - accuracy: 0.8845 - val_loss: 0.4166 - val_accuracy: 0.8650\n",
            "Epoch 48/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3337 - accuracy: 0.8838 - val_loss: 0.4051 - val_accuracy: 0.8674\n",
            "Epoch 49/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3332 - accuracy: 0.8848 - val_loss: 0.4100 - val_accuracy: 0.8673\n",
            "Epoch 50/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3301 - accuracy: 0.8862 - val_loss: 0.4377 - val_accuracy: 0.8611\n",
            "Epoch 51/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3282 - accuracy: 0.8866 - val_loss: 0.4262 - val_accuracy: 0.8663\n",
            "Epoch 52/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3300 - accuracy: 0.8850 - val_loss: 0.4326 - val_accuracy: 0.8630\n",
            "Epoch 53/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3234 - accuracy: 0.8887 - val_loss: 0.4243 - val_accuracy: 0.8663\n",
            "Epoch 54/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3188 - accuracy: 0.8892 - val_loss: 0.4187 - val_accuracy: 0.8704\n",
            "Epoch 55/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3185 - accuracy: 0.8898 - val_loss: 0.4053 - val_accuracy: 0.8690\n",
            "Epoch 56/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3158 - accuracy: 0.8912 - val_loss: 0.4423 - val_accuracy: 0.8609\n",
            "Epoch 57/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3108 - accuracy: 0.8910 - val_loss: 0.4050 - val_accuracy: 0.8704\n",
            "Epoch 58/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3104 - accuracy: 0.8920 - val_loss: 0.4155 - val_accuracy: 0.8664\n",
            "Epoch 59/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3080 - accuracy: 0.8929 - val_loss: 0.4117 - val_accuracy: 0.8731\n",
            "Epoch 60/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3051 - accuracy: 0.8941 - val_loss: 0.4071 - val_accuracy: 0.8699\n",
            "Epoch 61/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3010 - accuracy: 0.8958 - val_loss: 0.4044 - val_accuracy: 0.8708\n",
            "Epoch 62/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3032 - accuracy: 0.8963 - val_loss: 0.3942 - val_accuracy: 0.8728\n",
            "Epoch 63/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3027 - accuracy: 0.8963 - val_loss: 0.4113 - val_accuracy: 0.8685\n",
            "Epoch 64/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2950 - accuracy: 0.8966 - val_loss: 0.4028 - val_accuracy: 0.8722\n",
            "Epoch 65/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2984 - accuracy: 0.8974 - val_loss: 0.4020 - val_accuracy: 0.8733\n",
            "Epoch 66/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2966 - accuracy: 0.8974 - val_loss: 0.4022 - val_accuracy: 0.8744\n",
            "Epoch 67/100\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.2921 - accuracy: 0.8979 - val_loss: 0.3986 - val_accuracy: 0.8735\n",
            "Epoch 68/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2945 - accuracy: 0.8976 - val_loss: 0.3917 - val_accuracy: 0.8778\n",
            "Epoch 69/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2938 - accuracy: 0.8980 - val_loss: 0.3952 - val_accuracy: 0.8726\n",
            "Epoch 70/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2892 - accuracy: 0.9009 - val_loss: 0.3934 - val_accuracy: 0.8764\n",
            "Epoch 71/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2816 - accuracy: 0.9030 - val_loss: 0.4108 - val_accuracy: 0.8725\n",
            "Epoch 72/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2828 - accuracy: 0.9000 - val_loss: 0.4199 - val_accuracy: 0.8734\n",
            "Epoch 73/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2808 - accuracy: 0.9016 - val_loss: 0.4179 - val_accuracy: 0.8667\n",
            "Epoch 74/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2804 - accuracy: 0.9012 - val_loss: 0.4261 - val_accuracy: 0.8678\n",
            "Epoch 75/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2827 - accuracy: 0.9014 - val_loss: 0.4193 - val_accuracy: 0.8684\n",
            "Epoch 76/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2781 - accuracy: 0.9022 - val_loss: 0.4047 - val_accuracy: 0.8738\n",
            "Epoch 77/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2781 - accuracy: 0.9023 - val_loss: 0.4418 - val_accuracy: 0.8631\n",
            "Epoch 78/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2763 - accuracy: 0.9048 - val_loss: 0.4362 - val_accuracy: 0.8631\n",
            "Epoch 79/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2786 - accuracy: 0.9033 - val_loss: 0.4037 - val_accuracy: 0.8735\n",
            "Epoch 80/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2759 - accuracy: 0.9030 - val_loss: 0.4039 - val_accuracy: 0.8747\n",
            "Epoch 81/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2755 - accuracy: 0.9051 - val_loss: 0.4182 - val_accuracy: 0.8700\n",
            "Epoch 82/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2728 - accuracy: 0.9050 - val_loss: 0.4370 - val_accuracy: 0.8693\n",
            "Epoch 83/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2704 - accuracy: 0.9052 - val_loss: 0.4233 - val_accuracy: 0.8718\n",
            "Epoch 84/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2677 - accuracy: 0.9063 - val_loss: 0.3902 - val_accuracy: 0.8812\n",
            "Epoch 85/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2653 - accuracy: 0.9075 - val_loss: 0.4161 - val_accuracy: 0.8747\n",
            "Epoch 86/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2677 - accuracy: 0.9070 - val_loss: 0.4073 - val_accuracy: 0.8714\n",
            "Epoch 87/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2641 - accuracy: 0.9068 - val_loss: 0.4233 - val_accuracy: 0.8689\n",
            "Epoch 88/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2623 - accuracy: 0.9091 - val_loss: 0.4098 - val_accuracy: 0.8757\n",
            "Epoch 89/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2685 - accuracy: 0.9071 - val_loss: 0.3994 - val_accuracy: 0.8759\n",
            "Epoch 90/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2626 - accuracy: 0.9092 - val_loss: 0.3892 - val_accuracy: 0.8807\n",
            "Epoch 91/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2544 - accuracy: 0.9110 - val_loss: 0.3893 - val_accuracy: 0.8808\n",
            "Epoch 92/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2604 - accuracy: 0.9087 - val_loss: 0.4152 - val_accuracy: 0.8731\n",
            "Epoch 93/100\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.2607 - accuracy: 0.9083 - val_loss: 0.4174 - val_accuracy: 0.8719\n",
            "Epoch 94/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2525 - accuracy: 0.9122 - val_loss: 0.4156 - val_accuracy: 0.8736\n",
            "Epoch 95/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2580 - accuracy: 0.9115 - val_loss: 0.3964 - val_accuracy: 0.8750\n",
            "Epoch 96/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2558 - accuracy: 0.9122 - val_loss: 0.4063 - val_accuracy: 0.8771\n",
            "Epoch 97/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2541 - accuracy: 0.9119 - val_loss: 0.3983 - val_accuracy: 0.8731\n",
            "Epoch 98/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2522 - accuracy: 0.9117 - val_loss: 0.4414 - val_accuracy: 0.8667\n",
            "Epoch 99/100\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2501 - accuracy: 0.9136 - val_loss: 0.3924 - val_accuracy: 0.8813\n",
            "Epoch 100/100\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.2487 - accuracy: 0.9130 - val_loss: 0.3984 - val_accuracy: 0.8775\n"
          ]
        }
      ]
    }
  ]
}